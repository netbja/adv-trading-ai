"""
‚è∞ AI SCHEDULER
Planificateur intelligent qui remplace les crons traditionnels
"""

import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, asdict
import logging

from celery import Celery
from sqlalchemy.orm import Session
from redis import Redis

from .decision_engine import DecisionEngine, TaskType, Priority, TaskRecommendation

import sys
sys.path.append('/app/backend')
from database.connection import get_db
from utils.logger import get_logger
# Note: ces imports seront corrig√©s une fois les t√¢ches cr√©√©es
# from ..tasks.celery_app import celery_app

logger = get_logger(__name__)

@dataclass
class ScheduledTask:
    id: str
    task_type: TaskType
    priority: Priority
    next_execution: datetime
    frequency_minutes: int
    celery_task_name: str
    parameters: Dict
    last_execution: Optional[datetime] = None
    execution_count: int = 0
    success_count: int = 0
    failure_count: int = 0
    avg_execution_time: float = 0.0
    reason: str = ""

class AIScheduler:
    """
    ‚è∞ Planificateur intelligent de t√¢ches
    
    Remplace les crons traditionnels par une IA qui adapte 
    dynamiquement la planification selon les conditions.
    """
    
    def __init__(self, redis_client: Optional[Redis] = None):
        self.decision_engine = DecisionEngine()
        self.redis_client = redis_client
        self.scheduled_tasks: Dict[str, ScheduledTask] = {}
        self.running = False
        self.task_registry = self._build_task_registry()
        
    def _build_task_registry(self) -> Dict[TaskType, str]:
        """Mappage des types de t√¢ches vers les t√¢ches Celery"""
        return {
            # Workflows g√©n√©riques
            TaskType.MARKET_ANALYSIS: "app.tasks.ai_tasks.ai_market_analysis",
            TaskType.SYSTEM_HEALTH: "app.tasks.monitoring_tasks.system_health_check",
            TaskType.DATA_SYNC: "app.tasks.trading_tasks.sync_market_data",
            TaskType.AI_LEARNING: "app.tasks.ai_tasks.ai_learning_update",
            TaskType.RISK_ASSESSMENT: "app.tasks.trading_tasks.risk_assessment",
            
            # ü™ô MEME COINS WORKFLOW
            TaskType.MEME_ANALYSIS: "app.tasks.meme_tasks.analyze_meme_trends",
            TaskType.MEME_TRADING: "app.tasks.meme_tasks.execute_meme_trades",
            TaskType.MEME_MONITORING: "app.tasks.meme_tasks.monitor_meme_positions",
            
            # ‚Çø CRYPTO LONG TERME WORKFLOW
            TaskType.CRYPTO_LT_ANALYSIS: "app.tasks.crypto_tasks.analyze_crypto_longterm",
            TaskType.CRYPTO_LT_TRADING: "app.tasks.crypto_tasks.execute_crypto_dca",
            TaskType.CRYPTO_LT_REBALANCING: "app.tasks.crypto_tasks.rebalance_crypto_portfolio",
            
            # üí± FOREX WORKFLOW
            TaskType.FOREX_ANALYSIS: "app.tasks.forex_tasks.analyze_forex_pairs",
            TaskType.FOREX_TRADING: "app.tasks.forex_tasks.execute_forex_trades",
            TaskType.FOREX_CORRELATION: "app.tasks.forex_tasks.analyze_forex_correlations",
            
            # üìà ETF WORKFLOW
            TaskType.ETF_ANALYSIS: "app.tasks.etf_tasks.analyze_etf_performance",
            TaskType.ETF_TRADING: "app.tasks.etf_tasks.execute_etf_trades",
            TaskType.ETF_REBALANCING: "app.tasks.etf_tasks.rebalance_etf_portfolio",
            
            # Legacy (compatibilit√©)
            TaskType.TRADING_EXECUTION: "app.tasks.trading_tasks.execute_trading_signal"
        }

    async def start(self):
        """D√©marre l'orchestrateur AI"""
        logger.info("üöÄ D√©marrage de l'Orchestrateur AI")
        self.running = True
        
        # Initialisation des t√¢ches de base
        await self._initialize_base_tasks()
        
        # Boucle principale de l'orchestrateur
        await self._main_loop()

    async def stop(self):
        """Arr√™te l'orchestrateur AI"""
        logger.info("üõë Arr√™t de l'Orchestrateur AI")
        self.running = False

    async def _initialize_base_tasks(self):
        """Initialise les t√¢ches de base du syst√®me"""
        
        # T√¢ches critiques toujours pr√©sentes
        base_tasks = [
            ScheduledTask(
                id="system_health_monitor",
                task_type=TaskType.SYSTEM_HEALTH,
                priority=Priority.CRITICAL,
                next_execution=datetime.utcnow(),
                frequency_minutes=5,
                celery_task_name=self.task_registry[TaskType.SYSTEM_HEALTH],
                parameters={},
                reason="T√¢che syst√®me critique"
            ),
            ScheduledTask(
                id="market_data_sync",
                task_type=TaskType.DATA_SYNC,
                priority=Priority.HIGH,
                next_execution=datetime.utcnow() + timedelta(minutes=1),
                frequency_minutes=5,
                celery_task_name=self.task_registry[TaskType.DATA_SYNC],
                parameters={},
                reason="Synchronisation donn√©es de base"
            )
        ]
        
        for task in base_tasks:
            self.scheduled_tasks[task.id] = task
            
        logger.info(f"üìã {len(base_tasks)} t√¢ches de base initialis√©es")

    async def _main_loop(self):
        """Boucle principale de l'orchestrateur"""
        
        loop_count = 0
        
        while self.running:
            try:
                loop_count += 1
                logger.info(f"üîÑ Cycle orchestrateur #{loop_count}")
                
                # 1. Analyser les conditions actuelles
                market_condition, system_status = await self.decision_engine.analyze_current_conditions()
                
                # 2. G√©n√©rer les recommandations
                recommendations = await self.decision_engine.generate_recommendations(
                    market_condition, system_status
                )
                
                # 3. Mettre √† jour le planning
                await self._update_schedule(recommendations)
                
                # 4. Ex√©cuter les t√¢ches pr√™tes
                await self._execute_ready_tasks()
                
                # 5. Nettoyer les t√¢ches obsol√®tes
                await self._cleanup_tasks()
                
                # 6. Persister l'√©tat
                await self._persist_state()
                
                # 7. Attendre avant le prochain cycle
                await asyncio.sleep(30)  # Cycle toutes les 30 secondes
                
            except Exception as e:
                logger.error(f"‚ùå Erreur dans la boucle principale: {e}")
                await asyncio.sleep(60)  # Attendre plus longtemps en cas d'erreur

    async def _update_schedule(self, recommendations: List[TaskRecommendation]):
        """Met √† jour le planning selon les recommandations de l'IA"""
        
        for rec in recommendations:
            task_id = f"{rec.task_type.value}_{rec.priority.name.lower()}"
            
            if task_id in self.scheduled_tasks:
                # Mettre √† jour une t√¢che existante
                task = self.scheduled_tasks[task_id]
                
                # Adapter la fr√©quence si n√©cessaire
                if task.frequency_minutes != rec.frequency_minutes:
                    logger.info(f"üîÑ Ajustement fr√©quence {task_id}: "
                              f"{task.frequency_minutes} ‚Üí {rec.frequency_minutes} min")
                    task.frequency_minutes = rec.frequency_minutes
                    
                # Mettre √† jour les param√®tres
                task.parameters.update(rec.parameters)
                task.priority = rec.priority
                task.reason = rec.reason
                
            else:
                # Cr√©er une nouvelle t√¢che
                if rec.task_type in self.task_registry:
                    new_task = ScheduledTask(
                        id=task_id,
                        task_type=rec.task_type,
                        priority=rec.priority,
                        next_execution=datetime.utcnow() + timedelta(minutes=1),
                        frequency_minutes=rec.frequency_minutes,
                        celery_task_name=self.task_registry[rec.task_type],
                        parameters=rec.parameters,
                        reason=rec.reason
                    )
                    
                    self.scheduled_tasks[task_id] = new_task
                    logger.info(f"‚ûï Nouvelle t√¢che planifi√©e: {task_id}")

    async def _execute_ready_tasks(self):
        """Ex√©cute les t√¢ches pr√™tes √† √™tre lanc√©es"""
        
        now = datetime.utcnow()
        ready_tasks = [
            task for task in self.scheduled_tasks.values()
            if task.next_execution <= now
        ]
        
        if not ready_tasks:
            return
            
        logger.info(f"üéØ {len(ready_tasks)} t√¢ches pr√™tes √† l'ex√©cution")
        
        # Trier par priorit√©
        ready_tasks.sort(key=lambda t: t.priority.value)
        
        for task in ready_tasks:
            try:
                await self._execute_task(task)
            except Exception as e:
                logger.error(f"‚ùå Erreur ex√©cution t√¢che {task.id}: {e}")
                task.failure_count += 1

    async def _execute_task(self, task: ScheduledTask):
        """Ex√©cute une t√¢che sp√©cifique"""
        
        start_time = datetime.utcnow()
        
        logger.info(f"üöÄ Ex√©cution t√¢che: {task.id} (priorit√©: {task.priority.name})")
        
        try:
            # TODO: Lancer la t√¢che Celery (temporairement d√©sactiv√©)
            # celery_task = celery_app.send_task(
            #     task.celery_task_name,
            #     kwargs=task.parameters
            # )
            
            # Simulation d'ex√©cution pour le moment
            logger.info(f"üìã Simulation ex√©cution t√¢che: {task.celery_task_name}")
            await asyncio.sleep(0.1)  # Simulation d'une t√¢che rapide
            
            # Attendre le r√©sultat (optionnel, pour tracking)
            # result = celery_task.get(timeout=300)  # 5 minutes timeout
            
            # Mise √† jour des statistiques
            execution_time = (datetime.utcnow() - start_time).total_seconds()
            task.last_execution = start_time
            task.execution_count += 1
            task.success_count += 1
            
            # Mise √† jour temps d'ex√©cution moyen
            if task.avg_execution_time == 0:
                task.avg_execution_time = execution_time
            else:
                task.avg_execution_time = (task.avg_execution_time + execution_time) / 2
            
            # Programmer la prochaine ex√©cution
            task.next_execution = start_time + timedelta(minutes=task.frequency_minutes)
            
            logger.info(f"‚úÖ T√¢che {task.id} ex√©cut√©e avec succ√®s en {execution_time:.2f}s")
            
        except Exception as e:
            task.failure_count += 1
            logger.error(f"‚ùå √âchec ex√©cution t√¢che {task.id}: {e}")
            
            # Retarder la prochaine ex√©cution en cas d'√©chec
            delay_minutes = min(task.frequency_minutes * 2, 30)  # Max 30 min de d√©lai
            task.next_execution = datetime.utcnow() + timedelta(minutes=delay_minutes)

    async def _cleanup_tasks(self):
        """Nettoie les t√¢ches obsol√®tes ou en √©chec"""
        
        tasks_to_remove = []
        
        for task_id, task in self.scheduled_tasks.items():
            # Supprimer les t√¢ches avec trop d'√©checs
            if task.execution_count > 0:
                failure_rate = task.failure_count / task.execution_count
                if failure_rate > 0.8 and task.execution_count > 5:
                    logger.warning(f"üóëÔ∏è Suppression t√¢che en √©chec: {task_id} "
                                 f"(taux d'√©chec: {failure_rate:.1%})")
                    tasks_to_remove.append(task_id)
        
        for task_id in tasks_to_remove:
            del self.scheduled_tasks[task_id]

    async def _persist_state(self):
        """Persiste l'√©tat de l'orchestrateur dans Redis"""
        
        if not self.redis_client:
            return
            
        try:
            state = {
                "timestamp": datetime.utcnow().isoformat(),
                "tasks_count": len(self.scheduled_tasks),
                "tasks": {
                    task_id: {
                        "task_type": task.task_type.value,
                        "priority": task.priority.name,
                        "next_execution": task.next_execution.isoformat(),
                        "frequency_minutes": task.frequency_minutes,
                        "execution_count": task.execution_count,
                        "success_count": task.success_count,
                        "failure_count": task.failure_count,
                        "avg_execution_time": task.avg_execution_time,
                        "reason": task.reason
                    }
                    for task_id, task in self.scheduled_tasks.items()
                }
            }
            
            self.redis_client.set(
                "orchestrator:state",
                json.dumps(state, default=str),
                ex=3600  # Expire dans 1 heure
            )
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde √©tat: {e}")

    def get_status(self) -> Dict:
        """Retourne le statut actuel de l'orchestrateur"""
        
        total_tasks = len(self.scheduled_tasks)
        total_executions = sum(task.execution_count for task in self.scheduled_tasks.values())
        total_successes = sum(task.success_count for task in self.scheduled_tasks.values())
        
        success_rate = (total_successes / total_executions * 100) if total_executions > 0 else 0
        
        return {
            "running": self.running,
            "total_tasks": total_tasks,
            "total_executions": total_executions,
            "success_rate": round(success_rate, 1),
            "tasks": [
                {
                    "id": task.id,
                    "type": task.task_type.value,
                    "priority": task.priority.name,
                    "next_execution": task.next_execution.isoformat(),
                    "frequency_minutes": task.frequency_minutes,
                    "execution_count": task.execution_count,
                    "success_rate": round((task.success_count / task.execution_count * 100) if task.execution_count > 0 else 0, 1),
                    "avg_execution_time": round(task.avg_execution_time, 2),
                    "reason": task.reason
                }
                for task in sorted(self.scheduled_tasks.values(), key=lambda t: t.priority.value)
            ]
        } 