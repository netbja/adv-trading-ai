"""
üß† AI FEEDBACK LOOP - BOUCLE DE R√âTROACTION POSITIVE
====================================================

Ce module impl√©mente l'intelligence auto-am√©liorante de l'orchestrateur :
- Analyse des performances pass√©es
- Apprentissage automatique des patterns
- Optimisation continue des d√©cisions
- Adaptation aux conditions de march√© changeantes
"""

import logging
import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import numpy as np

from database.connection import get_db_session
from app.orchestrator.decision_engine import DecisionEngine
from app.orchestrator.performance_tracker import PerformanceTracker

logger = logging.getLogger(__name__)

class LearningSignal(Enum):
    """Types de signaux d'apprentissage"""
    SUCCESS = "success"
    FAILURE = "failure" 
    OPTIMIZATION = "optimization"
    ADAPTATION = "adaptation"

@dataclass
class FeedbackData:
    """Donn√©es de r√©troaction pour l'apprentissage"""
    timestamp: datetime
    asset_type: str
    decision_id: str
    market_conditions: Dict
    system_conditions: Dict
    action_taken: str
    result_metrics: Dict
    learning_signal: LearningSignal
    confidence_score: float

@dataclass
class LearningPattern:
    """Pattern appris par l'IA"""
    pattern_id: str
    market_signature: Dict  # Signature des conditions de march√©
    system_signature: Dict  # Signature des conditions syst√®me
    optimal_action: str
    success_rate: float
    confidence: float
    usage_count: int
    last_updated: datetime

class AIFeedbackLoop:
    """
    üß† BOUCLE DE R√âTROACTION IA POSITIVE
    
    Cette classe impl√©mente l'apprentissage continu de l'orchestrateur :
    - Collecte automatique des m√©triques de performance
    - Identification des patterns de succ√®s/√©chec
    - Optimisation des d√©cisions futures
    - Adaptation aux nouvelles conditions
    """
    
    def __init__(self, decision_engine: DecisionEngine, performance_tracker: PerformanceTracker):
        self.decision_engine = decision_engine
        self.performance_tracker = performance_tracker
        self.learned_patterns: Dict[str, LearningPattern] = {}
        self.feedback_history: List[FeedbackData] = []
        self.learning_rate = 0.1
        self.confidence_threshold = 0.7
        
        # M√©triques d'apprentissage
        self.total_learning_cycles = 0
        self.patterns_discovered = 0
        self.decisions_optimized = 0
        self.adaptation_score = 0.0
        
        logger.info("üß† AI Feedback Loop initialis√© - Apprentissage continu activ√©")

    async def process_feedback(self, feedback: FeedbackData) -> Dict:
        """
        üîÑ Traiter une r√©troaction et d√©clencher l'apprentissage
        
        Args:
            feedback: Donn√©es de r√©troaction √† analyser
            
        Returns:
            Dict contenant les insights de l'apprentissage
        """
        try:
            # 1. Stocker la r√©troaction
            self.feedback_history.append(feedback)
            
            # 2. Analyser et apprendre
            learning_insights = await self._analyze_and_learn(feedback)
            
            # 3. Mettre √† jour les patterns
            await self._update_patterns(feedback, learning_insights)
            
            # 4. Optimiser les d√©cisions futures
            optimization_impact = await self._optimize_future_decisions(feedback)
            
            # 5. Calculer le score d'adaptation
            self.adaptation_score = await self._calculate_adaptation_score()
            
            self.total_learning_cycles += 1
            
            result = {
                "feedback_processed": True,
                "learning_insights": learning_insights,
                "optimization_impact": optimization_impact,
                "adaptation_score": self.adaptation_score,
                "patterns_count": len(self.learned_patterns),
                "learning_cycle": self.total_learning_cycles
            }
            
            logger.info(f"üß† Feedback trait√© - Cycle #{self.total_learning_cycles} - Score adaptation: {self.adaptation_score:.3f}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement feedback: {e}")
            return {"feedback_processed": False, "error": str(e)}

    async def _analyze_and_learn(self, feedback: FeedbackData) -> Dict:
        """üîç Analyser la r√©troaction et extraire des insights"""
        
        insights = {
            "market_pattern_detected": False,
            "system_correlation_found": False,
            "new_strategy_learned": False,
            "confidence_adjustment": 0.0
        }
        
        try:
            # Analyser les conditions de march√© lors du succ√®s/√©chec
            market_signature = self._extract_market_signature(feedback.market_conditions)
            system_signature = self._extract_system_signature(feedback.system_conditions)
            
            # Rechercher des patterns similaires
            similar_patterns = self._find_similar_patterns(market_signature, system_signature)
            
            if feedback.learning_signal == LearningSignal.SUCCESS:
                insights = await self._learn_from_success(feedback, similar_patterns)
            elif feedback.learning_signal == LearningSignal.FAILURE:
                insights = await self._learn_from_failure(feedback, similar_patterns)
            
            # Ajuster la confiance globale
            insights["confidence_adjustment"] = self._calculate_confidence_adjustment(feedback)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse apprentissage: {e}")
            
        return insights

    async def _learn_from_success(self, feedback: FeedbackData, similar_patterns: List[LearningPattern]) -> Dict:
        """‚úÖ Apprendre des succ√®s pour renforcer les bonnes d√©cisions"""
        
        insights = {
            "success_pattern_reinforced": False,
            "new_optimal_strategy": None,
            "confidence_boost": 0.0
        }
        
        try:
            # Renforcer les patterns existants
            for pattern in similar_patterns:
                pattern.success_rate = min(1.0, pattern.success_rate + self.learning_rate)
                pattern.confidence = min(1.0, pattern.confidence + 0.05)
                pattern.usage_count += 1
                pattern.last_updated = datetime.utcnow()
                insights["success_pattern_reinforced"] = True
            
            # Cr√©er un nouveau pattern si aucun similaire
            if not similar_patterns:
                new_pattern = self._create_new_pattern(feedback, success_bias=True)
                if new_pattern:
                    self.learned_patterns[new_pattern.pattern_id] = new_pattern
                    self.patterns_discovered += 1
                    insights["new_optimal_strategy"] = new_pattern.optimal_action
            
            # Boost de confiance pour ce type de d√©cision
            insights["confidence_boost"] = min(0.2, feedback.confidence_score * 0.1)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur apprentissage succ√®s: {e}")
            
        return insights

    async def _learn_from_failure(self, feedback: FeedbackData, similar_patterns: List[LearningPattern]) -> Dict:
        """‚ùå Apprendre des √©checs pour √©viter les erreurs"""
        
        insights = {
            "failure_pattern_identified": False,
            "strategy_adjustment": None,
            "confidence_penalty": 0.0
        }
        
        try:
            # P√©naliser les patterns qui ont √©chou√©
            for pattern in similar_patterns:
                pattern.success_rate = max(0.0, pattern.success_rate - self.learning_rate)
                pattern.confidence = max(0.1, pattern.confidence - 0.1)
                pattern.last_updated = datetime.utcnow()
                insights["failure_pattern_identified"] = True
            
            # Marquer cette combinaison comme probl√©matique
            failure_signature = {
                "market": self._extract_market_signature(feedback.market_conditions),
                "system": self._extract_system_signature(feedback.system_conditions),
                "action": feedback.action_taken,
                "avoid": True
            }
            
            # Chercher une strat√©gie alternative
            alternative_action = await self._find_alternative_strategy(feedback)
            if alternative_action:
                insights["strategy_adjustment"] = alternative_action
            
            # P√©nalit√© de confiance
            insights["confidence_penalty"] = min(0.3, feedback.confidence_score * 0.15)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur apprentissage √©chec: {e}")
            
        return insights

    def _extract_market_signature(self, market_conditions: Dict) -> Dict:
        """üìä Extraire une signature des conditions de march√©"""
        
        signature = {}
        
        try:
            # Volatilit√© (par tranches)
            volatility = market_conditions.get("volatility", 0.2)
            if volatility > 0.8:
                signature["volatility_level"] = "high"
            elif volatility < 0.4:
                signature["volatility_level"] = "low"
            else:
                signature["volatility_level"] = "medium"
            
            # Tendance
            trend = market_conditions.get("trend_strength", 0.0)
            signature["trend"] = "bullish" if trend > 0.1 else "bearish" if trend < -0.1 else "neutral"
            
            # Session de trading (pour forex)
            hour = datetime.utcnow().hour
            if 8 <= hour <= 17:
                signature["trading_session"] = "active"
            else:
                signature["trading_session"] = "inactive"
                
        except Exception as e:
            logger.error(f"‚ùå Erreur extraction signature march√©: {e}")
            
        return signature

    def _extract_system_signature(self, system_conditions: Dict) -> Dict:
        """üñ•Ô∏è Extraire une signature des conditions syst√®me"""
        
        signature = {}
        
        try:
            # CPU
            cpu = system_conditions.get("cpu_usage", 30)
            signature["cpu_load"] = "high" if cpu > 80 else "medium" if cpu > 50 else "low"
            
            # M√©moire
            memory = system_conditions.get("memory_usage", 40)
            signature["memory_load"] = "high" if memory > 85 else "medium" if memory > 60 else "low"
            
            # Connexions
            connections = system_conditions.get("active_connections", 5)
            signature["connection_load"] = "high" if connections > 20 else "low"
            
        except Exception as e:
            logger.error(f"‚ùå Erreur extraction signature syst√®me: {e}")
            
        return signature

    def _find_similar_patterns(self, market_sig: Dict, system_sig: Dict) -> List[LearningPattern]:
        """üîç Trouver des patterns similaires dans l'historique"""
        
        similar = []
        
        try:
            for pattern in self.learned_patterns.values():
                market_similarity = self._calculate_signature_similarity(
                    market_sig, pattern.market_signature
                )
                system_similarity = self._calculate_signature_similarity(
                    system_sig, pattern.system_signature
                )
                
                # Seuil de similarit√©
                if market_similarity > 0.7 and system_similarity > 0.5:
                    similar.append(pattern)
                    
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche patterns similaires: {e}")
            
        return similar

    def _calculate_signature_similarity(self, sig1: Dict, sig2: Dict) -> float:
        """üìè Calculer la similarit√© entre deux signatures"""
        
        if not sig1 or not sig2:
            return 0.0
            
        common_keys = set(sig1.keys()) & set(sig2.keys())
        if not common_keys:
            return 0.0
            
        matches = sum(1 for key in common_keys if sig1[key] == sig2[key])
        return matches / len(common_keys)

    def _create_new_pattern(self, feedback: FeedbackData, success_bias: bool = False) -> Optional[LearningPattern]:
        """üÜï Cr√©er un nouveau pattern d'apprentissage"""
        
        try:
            pattern_id = f"pattern_{len(self.learned_patterns)}_{feedback.asset_type}_{int(datetime.utcnow().timestamp())}"
            
            pattern = LearningPattern(
                pattern_id=pattern_id,
                market_signature=self._extract_market_signature(feedback.market_conditions),
                system_signature=self._extract_system_signature(feedback.system_conditions),
                optimal_action=feedback.action_taken,
                success_rate=0.8 if success_bias else 0.3,
                confidence=feedback.confidence_score,
                usage_count=1,
                last_updated=datetime.utcnow()
            )
            
            return pattern
            
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation nouveau pattern: {e}")
            return None

    async def _optimize_future_decisions(self, feedback: FeedbackData) -> Dict:
        """‚ö° Optimiser les d√©cisions futures bas√©es sur l'apprentissage"""
        
        optimization = {
            "decision_rules_updated": False,
            "frequency_adjustments": {},
            "priority_rebalancing": {},
            "new_thresholds": {}
        }
        
        try:
            # Ajuster les fr√©quences selon la performance
            if feedback.learning_signal == LearningSignal.SUCCESS:
                # Augmenter la fr√©quence des actions qui r√©ussissent
                optimization["frequency_adjustments"][feedback.action_taken] = "increase"
            elif feedback.learning_signal == LearningSignal.FAILURE:
                # Diminuer la fr√©quence des actions qui √©chouent
                optimization["frequency_adjustments"][feedback.action_taken] = "decrease"
            
            # Mettre √† jour les seuils de d√©cision
            await self._update_decision_thresholds(feedback, optimization)
            
            self.decisions_optimized += 1
            optimization["decision_rules_updated"] = True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur optimisation d√©cisions: {e}")
            
        return optimization

    async def _update_decision_thresholds(self, feedback: FeedbackData, optimization: Dict):
        """üéØ Mettre √† jour les seuils de d√©cision"""
        
        try:
            # Ajuster les seuils de volatilit√© pour les meme coins
            if feedback.asset_type == "meme_coins":
                current_volatility = feedback.market_conditions.get("volatility", 0.8)
                
                if feedback.learning_signal == LearningSignal.SUCCESS and current_volatility < 0.8:
                    # Si succ√®s avec volatilit√© plus faible, assouplir le seuil
                    new_threshold = max(0.6, current_volatility - 0.05)
                    optimization["new_thresholds"]["meme_coins_volatility"] = new_threshold
                elif feedback.learning_signal == LearningSignal.FAILURE and current_volatility >= 0.8:
                    # Si √©chec malgr√© volatilit√© √©lev√©e, durcir le seuil
                    new_threshold = min(1.0, current_volatility + 0.05)
                    optimization["new_thresholds"]["meme_coins_volatility"] = new_threshold
                    
        except Exception as e:
            logger.error(f"‚ùå Erreur mise √† jour seuils: {e}")

    async def _calculate_adaptation_score(self) -> float:
        """üìà Calculer le score d'adaptation de l'IA"""
        
        try:
            if not self.feedback_history:
                return 0.0
            
            # Calculer le taux de succ√®s r√©cent
            recent_feedback = self.feedback_history[-20:]  # 20 derniers feedbacks
            success_count = sum(1 for f in recent_feedback if f.learning_signal == LearningSignal.SUCCESS)
            success_rate = success_count / len(recent_feedback) if recent_feedback else 0.0
            
            # Facteur d'am√©lioration (compare les 10 premiers vs 10 derniers)
            if len(self.feedback_history) >= 20:
                early_success = sum(1 for f in self.feedback_history[:10] if f.learning_signal == LearningSignal.SUCCESS) / 10
                recent_success = sum(1 for f in self.feedback_history[-10:] if f.learning_signal == LearningSignal.SUCCESS) / 10
                improvement_factor = (recent_success - early_success + 1) / 2  # Normaliser entre 0 et 1
            else:
                improvement_factor = 0.5
            
            # Score final (pond√©ration: 60% succ√®s r√©cent, 40% am√©lioration)
            adaptation_score = (success_rate * 0.6) + (improvement_factor * 0.4)
            
            return min(1.0, max(0.0, adaptation_score))
            
        except Exception as e:
            logger.error(f"‚ùå Erreur calcul score adaptation: {e}")
            return 0.0

    async def get_learning_insights(self) -> Dict:
        """üìä Obtenir les insights de l'apprentissage en cours"""
        
        try:
            insights = {
                "total_learning_cycles": self.total_learning_cycles,
                "patterns_discovered": self.patterns_discovered,
                "decisions_optimized": self.decisions_optimized,
                "adaptation_score": self.adaptation_score,
                "confidence_level": self.confidence_threshold,
                "top_patterns": await self._get_top_patterns(),
                "learning_trends": await self._get_learning_trends(),
                "optimization_impact": await self._calculate_optimization_impact()
            }
            
            return insights
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration insights: {e}")
            return {}

    async def _get_top_patterns(self) -> List[Dict]:
        """üèÜ Obtenir les meilleurs patterns appris"""
        
        try:
            # Trier par taux de succ√®s et confiance
            sorted_patterns = sorted(
                self.learned_patterns.values(),
                key=lambda p: p.success_rate * p.confidence,
                reverse=True
            )
            
            top_patterns = []
            for pattern in sorted_patterns[:5]:  # Top 5
                top_patterns.append({
                    "pattern_id": pattern.pattern_id,
                    "optimal_action": pattern.optimal_action,
                    "success_rate": round(pattern.success_rate, 3),
                    "confidence": round(pattern.confidence, 3),
                    "usage_count": pattern.usage_count,
                    "market_conditions": pattern.market_signature
                })
                
            return top_patterns
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration top patterns: {e}")
            return []

    async def _get_learning_trends(self) -> Dict:
        """üìà Analyser les tendances d'apprentissage"""
        
        try:
            if len(self.feedback_history) < 10:
                return {"status": "insufficient_data"}
            
            # Analyser les 50 derniers feedbacks
            recent_feedback = self.feedback_history[-50:]
            
            # Taux de succ√®s par asset
            success_by_asset = {}
            for feedback in recent_feedback:
                asset = feedback.asset_type
                if asset not in success_by_asset:
                    success_by_asset[asset] = {"success": 0, "total": 0}
                
                success_by_asset[asset]["total"] += 1
                if feedback.learning_signal == LearningSignal.SUCCESS:
                    success_by_asset[asset]["success"] += 1
            
            # Calculer les taux
            trends = {}
            for asset, data in success_by_asset.items():
                trends[asset] = {
                    "success_rate": round(data["success"] / data["total"], 3) if data["total"] > 0 else 0,
                    "total_decisions": data["total"]
                }
            
            return trends
            
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse tendances: {e}")
            return {}

    async def _calculate_optimization_impact(self) -> Dict:
        """‚ö° Calculer l'impact des optimisations"""
        
        try:
            if self.decisions_optimized == 0:
                return {"impact": "no_optimizations_yet"}
            
            # Comparer les performances avant/apr√®s optimisations
            optimization_impact = {
                "decisions_optimized": self.decisions_optimized,
                "patterns_effectiveness": len([p for p in self.learned_patterns.values() if p.success_rate > 0.7]),
                "learning_velocity": self.total_learning_cycles / max(1, len(self.feedback_history)),
                "adaptation_trend": "improving" if self.adaptation_score > 0.6 else "stable" if self.adaptation_score > 0.4 else "learning"
            }
            
            return optimization_impact
            
        except Exception as e:
            logger.error(f"‚ùå Erreur calcul impact optimisation: {e}")
            return {}

    async def trigger_learning_cycle(self) -> Dict:
        """üîÑ D√©clencher manuellement un cycle d'apprentissage"""
        
        try:
            logger.info("üß† D√©clenchement cycle d'apprentissage manuel")
            
            # Analyser les performances r√©centes
            recent_metrics = await self.performance_tracker.get_recent_metrics()
            
            # Cr√©er un feedback de type optimisation
            optimization_feedback = FeedbackData(
                timestamp=datetime.utcnow(),
                asset_type="global",
                decision_id=f"optimization_{int(datetime.utcnow().timestamp())}",
                market_conditions=recent_metrics.get("market_conditions", {}),
                system_conditions=recent_metrics.get("system_status", {}),
                action_taken="optimization_review",
                result_metrics=recent_metrics,
                learning_signal=LearningSignal.OPTIMIZATION,
                confidence_score=0.8
            )
            
            # Traiter le feedback
            result = await self.process_feedback(optimization_feedback)
            
            logger.info(f"üß† Cycle d'apprentissage termin√© - Score adaptation: {self.adaptation_score:.3f}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur cycle d'apprentissage: {e}")
            return {"success": False, "error": str(e)}

# Instance globale pour l'injection de d√©pendance
_ai_feedback_loop: Optional[AIFeedbackLoop] = None

def get_ai_feedback_loop() -> AIFeedbackLoop:
    """üß† Obtenir l'instance de la boucle de r√©troaction IA"""
    global _ai_feedback_loop
    if _ai_feedback_loop is None:
        from app.orchestrator.decision_engine import get_decision_engine
        from app.orchestrator.performance_tracker import get_performance_tracker
        
        _ai_feedback_loop = AIFeedbackLoop(
            decision_engine=get_decision_engine(),
            performance_tracker=get_performance_tracker()
        )
    
    return _ai_feedback_loop 